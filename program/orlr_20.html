---
layout: paper
id: 20
slides_live_id: 38942934
rocket_id: orlr-paper-20
meeting_url: 
authors: "Danfei Xu, Ajay Mandlekar, Roberto Martín-Martín, Yuke Zhu, and Li Fei-Fei"
camera_ready: true
cmt_id: 20
kind: oral
session_id: 1
session_title: "Session TBD"
title: "Deep Affordance Foresight: Planning for What Can Be Done Next"
abstract: "Robotic planning in realistic environments requires searching in large planning spaces. A powerful concept for guiding the search is affordance, which models what actions can be successful in a given situation. However, the classical notion of affordance is unsuitable for planning because it only informs the robot about the immediate outcome of actions instead of what actions are best for achieving a long-term goal. In this paper, we introduce a new affordance representation and a learning-to-plan framework that enable the robot to reason about the long-term effects of actions through modeling what actions are possible in the future. We show that our method, Deep Affordance Foresight, can effectively learn multi-step tool-use tasks and quickly adapt to a new longer horizon task."
track: research
live: true
video_file_url: none
youtube_url: none
---