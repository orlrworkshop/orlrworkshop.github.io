---
layout: paper
id: 26
slides_live_id: 1
rocket_id: orlr-paper-26
meeting_url: 
authors: "Vidhi Jain, Shishir Patil, Prakhar Agarwal, and Katia Sycara"
camera_ready: true
cmt_id: 26
kind: poster
session_id: 1
session_title: "Session TBD"
title: "Learning Embeddings that Capture Spatial Semantics for Indoor Navigation"
abstract: "Incorporating domain-specific priors in search and navigation tasks has shown promising results in improving generalization and sample complexity over end-to-end trained policies. In this work, we study how object embeddings that capture spatial semantic priors can guide the search and navigation task in a structured environment. We know that humans can search for an object like a book, or a plate in an unseen house, based on spatial semantics of bigger objects detected. For example, a book is likely to be on a bookshelf or a table, whereas a plate is likely to be in a cupboard or dishwasher. We propose a method to incorporate such spatial semantic awareness in robots by leveraging pre-trained language models and multi-relational knowledge bases as object embeddings. We demonstrate the performance of using these object embeddings to search a query object in an unseen indoor environment. We measure the performance of these embeddings in an indoor simulator (AI2Thor). We further evaluate different pre-trained embedding on Success Rate (SR) and Success weighted by Path Length (SPL). Code is available at: https://github.com/vidhiJain/SpatialEmbeddings"
track: research
live: false
video_file_url: none
youtube_url: none
---