- abstract: TBD
  authors: Elizabeth Spelke
  id: 30
  kind: oral
  poster: false
  supplement: false
  title: TBD
- abstract: Physical construction---the ability to compose objects, subject to physical
    dynamics, to serve some function---is fundamental to human intelligence. In this
    talk, I will introduce a suite of challenging physical construction tasks inspired
    by how children play with blocks, such as matching a target configuration, stacking
    blocks to connect objects together, and creating shelter-like structures over
    target objects. I'll discuss a new way of creating object-centric, structured
    agents using graph representations, and show that such agents both outperform
    those which use less structured representations and generalize better beyond their
    training when asked to reason about larger scenes. Overall, I argue that agents
    which combine structured representations and reasoning with powerful learning
    are a key path toward agents that possess rich intuitive physics, scene understanding,
    and planning.
  authors: Jessica Hamrick
  id: 31
  kind: oral
  poster: false
  supplement: false
  title: Structured agents for object-centric reasoning
- abstract: We all seem to know intuitively what an object is, however the notion
    of an object appears to be very hard to define precisely. In order to move forward
    in building better object representations for learning and reasoning, it is important
    to first agree on what objects are. In this talk I will propose an operational
    definition of objects using insights from physics. I will then use this definition
    to suggest what a good object-centered representation should look like, and why
    it might be useful for more efficient and robust learning and reasoning.
  authors: Irina Higgins
  id: 32
  kind: oral
  poster: false
  supplement: false
  title: What is an object?
- abstract: 'Objects and their interactions are the foundational structure of the
    world that plays the central role in our perception, reasoning, and control of
    the world. Incorporating such structural knowledge is thus expected to resolve
    various limitations of current deep learning systems in reasoning, causality,
    modularity, and systematic generalization. However, current deep learning systems
    are limited in providing such structures: they either extensively rely on human
    annotations or uses unsupervised representations with a minimal uninterpretable
    structure. In this talk, I present recent advances in object-centric latent variable
    models. I first argue that this class of models provide a probabilistic modeling
    framework to learn interpretable, structured, and adaptable representations as
    well as the compositional imagination of multi-object scenes in an unsupervised
    manner. Also, I present the benefits of combining symbolic and distributed representations
    in these models, and an approach to learn three-dimensional scene representations
    in an object-centric manner. I conclude that human-like AI agents should understand
    the causal structured of the world and the object-centric representations can
    be the foundation of building such world models.'
  authors: Sungjin Ahn
  id: 33
  kind: oral
  poster: false
  supplement: false
  title: Unsupervising Vision via Object-Centric World Models
- abstract: 'First-person object-interaction tasks in high-fidelity, 3D, simulated
    environments such as the AI2Thor virtual home-environment pose significant sample-efficiency
    challenges for reinforcement learning (RL) agents learning from sparse task rewards.
    To alleviate these challenges, prior work has provided extensive supervision via
    a combination of reward-shaping, ground-truth object-information, and expert demonstrations.
    In this work, we show that one can learn object-interaction tasks from scratch
    without supervision by learning an attentive object-model as an auxiliary task
    during task learning with an object-centric relational RL agent. Our key insight
    is that learning an object-model that incorporates object-relationships into forward
    prediction provides a dense learning signal for unsupervised representation learning
    of both objects and their relationships. This, in turn, enables faster policy
    learning for an object-centric relational RL agent. We demonstrate our agent by
    introducing a set of challenging object-interaction tasks in the AI2Thor environment
    where learning with our attentive object-model is key to strong performance. Specifically,
    we compare our agent and relational RL agents with alternative auxiliary tasks
    to a relational RL agent equipped with ground-truth object-information, and show
    that learning with our object-model best closes the performance gap in terms of
    both learning speed and maximum success rate. '
  authors: Wilka Carvalho
  id: 34
  kind: oral
  poster: false
  supplement: false
  title: Learning Object-interaction Tasks with Less Supervision by Learning an Attentive
    Object-model
- abstract: "Research over the last few decades has shed considerable light on how\
    \ infants represent and reason about objects in simple physical events, such as\
    \ occlusion, containment, and support events. My talk summarizes key findings\
    \ from this research. First, representations of objects in physical events are\
    \ initially very sparse and lacking in featural detail; nevertheless, they are\
    \ still sufficient, when interpreted by infants\u2019 core physical knowledge,\
    \ to allow infants to correctly predict the outcomes of many physical events.\
    \ Second, object representations become richer and more detailed as infants form\
    \ event categories and, for each category, identify features that are causally\
    \ relevant for predicting outcomes. Third, once a feature has been identified\
    \ as relevant to an event category, it is represented for any event in the category,\
    \ thereby ensuring powerful generalization. Fourth, features identified in one\
    \ event category are not generalized to other event categories, even when equally\
    \ relevant, resulting at times in striking discrepancies in infants\u2019 responses\
    \ to similar events from different categories. Fifth, one of the learning mechanisms\
    \ by which infants identify features is explanation-based learning; because this\
    \ mechanism uses analytical as well as empirical evidence, it is highly efficient\
    \ and allows infants to acquire new featural rules with few exemplars. Finally,\
    \ the cognitive architecture that underlies early representations of objects in\
    \ physical reasoning includes at least two systems, an object-file and a physical-reasoning\
    \ system, each with a different role; understanding how each system represents\
    \ objects, how these representations change with experience, and how the two systems\
    \ exchange information as events unfold helps explain the findings described above.\
    \ Together, these findings make clear that object representations in infancy are\
    \ far from monolithic: They are both system-specific (the same object may be represented\
    \ differently in different systems) and event-specific (the same object may be\
    \ represented differently in different events), and they become gradually richer\
    \ with experience."
  authors: "Ren\xE9e Baillargeon"
  id: 35
  kind: oral
  poster: false
  supplement: false
  title: How Infants Represent Objects in Physical Events
- abstract: TBD
  authors: Dieter Fox
  id: 36
  kind: oral
  poster: false
  supplement: false
  title: TBD
